<?php
namespace Upress\Booter;

class RobotsWriter {
	private static $instance;
	/** @var bool */
	protected static $robots_file_exists;
	/** @var bool */
	protected static $is_robots_generated_by_booter;
	/** @var string */
	protected static $robots_path;

	/**
	 * @return RobotsWriter
	 */
	public static function initialize() {
		if ( ! self::$instance ) {
			self::$instance = new self;
		}

		return self::$instance;
	}


	private function __construct() {
		add_filter( 'cron_schedules', [ $this, 'add_cron_schedule' ] );
		add_action( 'booter_write_robots_file', [ $this, 'maybe_write_robots_file' ] );
		add_action( 'init', [ $this, 'schedule_cronjobs' ], 100 );
		register_deactivation_hook( BOOTER_FILE, [ $this, 'clear_scheduled_task' ] );

		if ( is_admin() ) {
			add_action( 'update_option_' . BOOTER_SETTINGS_KEY, [ $this, 'settings_save_write_robots' ], 10, 3 );
		}
	}

	/**
	 * Add custom cron schedule
	 * @param array $schedules
	 * @return mixed
	 */
	function add_cron_schedule( $schedules ) {
		if ( ! isset( $schedules['weekly'] ) ) {
			$schedules['weekly'] = [
				'interval' => 7 * DAY_IN_SECONDS,
				'display' => __( 'Once Weekly', 'booter' )
			];
		}

		return $schedules;
	}

	/**
	 * Schedule the cronjob
	 */
	function schedule_cronjobs() {
		if ( ! wp_next_scheduled( 'booter_write_robots_file' ) ) {
			$time = "1:00 am";
			$next_schedule = (strtotime($time) > time()) ? strtotime($time) : strtotime("tomorrow " . $time);
			wp_schedule_event( $next_schedule, 'weekly', 'booter_write_robots_file' );
		}
	}

	/**
	 * Canbcel the cronjob
	 */
	function clear_scheduled_task() {
		wp_clear_scheduled_hook( 'booter_write_robots_file' );
	}

	/**
	 * Intercept the settings save action and run the write robots function
	 *
	 * @param $old_value
	 * @param $value
	 * @param $option
	 */
	function settings_save_write_robots( $old_value, $value, $option ) {
		// save the robots.txt file
		$this->maybe_write_robots_file( $value );

		// re-schedule the daily cron
		$this->clear_scheduled_task();
		$this->schedule_cronjobs();
	}

	/**
	 * Get the path to the robots.txt file
	 * @return string
	 */
	public static function get_robots_path() {
		if ( ! self::$robots_path ) {
			include_once ABSPATH . '/wp-admin/includes/file.php';
			self::$robots_path = trailingslashit( get_home_path() ) . 'robots.txt';
		}

		return self::$robots_path;
	}

	/**
	 * Check if a robots.txt file exists
	 * @return bool
	 */
	public static function robots_file_exists() {
		if ( ! self::$robots_file_exists ) {
			self::$robots_file_exists = file_exists( self::get_robots_path() );
		}

		return self::$robots_file_exists;
	}

	/**
	 * Check if the robots.txt file is generated by Booter
	 * @return bool
	 */
	public static function is_robots_generated_by_booter() {
		if ( ! self::$is_robots_generated_by_booter ) {
			self::$is_robots_generated_by_booter = false !== stripos( file_get_contents( self::get_robots_path() ), 'Robots.txt generated by Booter - Crwalers Manager' );
		}

		return self::$is_robots_generated_by_booter;
	}

	/**
	 * Write the robots.txt file
	 * @param array|null $settings
	 */
	function maybe_write_robots_file( $settings = null ) {
		if ( ! $settings ) {
			$settings = get_option( 'booter_settings' );
		}

		if ( ! Utilities::bool_value( $settings['robots']['enabled'] ) ) {
			return;
		}

		// if a robots.txt file exists, and it is not ours, rename it to robots.txt.old
		$robots_path = self::get_robots_path();
		if ( self::robots_file_exists() && ! self::is_robots_generated_by_booter() ) {
			rename( $robots_path, $robots_path . '.' . time() . '.old' );
		}

		// create the new file
		$date = date( 'r' );
		$content = <<<EOF
# Robots.txt generated by Booter - Crwalers Manager at {$date}
# Do not modify this file, any contents will be overwritten


EOF;

		if ( Utilities::bool_value( $settings['robots']['block_all'] ) ) {
			$content .= "User-Agent: *\n";
			$content .= "Disallow: /\n";

			file_put_contents( $robots_path, $content );
			return;
		}

		if ( Utilities::bool_value( $settings['robots']['sitemap_enabled'] ) ) {
			$sitemap_url = esc_url( site_url( ! empty( $settings['robots']['sitemap_url'] ) ? '/' . trim( $settings['robots']['sitemap_url'], '/' ) : '/sitemap.xml' ) );
			$content .= "Sitemap: {$sitemap_url}\n\n";
		}

		$admin_url = trim( str_replace( esc_url_raw( site_url() ), '', esc_url_raw( admin_url() ) ), '/' );

		if ( isset( $settings['robots']['manage_type'] ) && 'simple' === $settings['robots']['manage_type'] ) {
			$content .= <<<EOF
User-Agent: *
Allow: /{$admin_url}/admin-ajax.php
Disallow: /{$admin_url}

EOF;
		} elseif ( ! empty( $settings['robots']['useragents'] ) ) {
			$settings['robots']['useragents'] = self::sanitize_robots_useragent( $settings['robots']['useragents'] );

			foreach ( $settings['robots']['useragents'] as $ua ) {
				if ( empty( $ua['useragent'] ) ) {
					continue;
				}

				$disallow = [];
				$allow    = [];
				$content .= "User-Agent: {$ua['useragent']}\n";

				if ( '0' != $ua['crawl_rate'] ) {
					$content .= "Crawl-Delay: {$ua['crawl_rate']}\n";
				}

				// add wp-admin / admin-ajax rules
				if ( Utilities::bool_value( $ua['restrict_wp_admin'] ) ) {
					$disallow[] = "/{$admin_url}";
				}
				if ( Utilities::bool_value( $ua['allow_wp_ajax'] ) ) {
					$allow[] = "/{$admin_url}/admin-ajax.php";
				}

				// filter and add the disallow list
				if ( ! empty( $ua['disallow'] ) ) {
					$ua['disallow'] = is_array( $ua['disallow'] ) ? $ua['disallow'] : json_decode( $ua['disallow'] );
					foreach ( $ua['disallow'] as $path ) {
						$path = str_replace( [ 'https://', 'http://' ], '', esc_url( $path ) );

						if ( Utilities::bool_value( $ua['restrict_wp_admin'] ) && preg_match( '/^\/?wp-admin\/?$/i', $path ) ) {
							continue;
						}

						// '/' or '/*' disallows everything so we don't need any other disallow rules
						if ( '/' == $path || '/*' == $path ) {
							$disallow = [ '/' ];
							break;
						}

						$disallow[] = $path;
					}
				}

				// filter and add allow list
				if ( ! empty( $ua['allow'] ) ) {
					$ua['allow'] = is_array( $ua['allow'] ) ? $ua['allow'] : json_decode( $ua['allow'] );
					foreach ( $ua['allow'] as $path ) {
						$path = str_replace( [ 'https://', 'http://' ], '', esc_url( $path ) );

						if ( Utilities::bool_value( $ua['allow_wp_ajax'] ) && preg_match( '/^\/?wp-admin\/admin-ajax.php$/i', $path ) ) {
							continue;
						}

						// '/' or '/*' allows everything so we don't need any other allow rules
						if ( '/' == $path || '/*' == $path ) {
							$allow = [ '/' ];
							break;
						}

						$allow[] = $path;
					}
				}

				// filter duplicates and add to the content
				$disallow = array_unique( $disallow );
				$disallow = array_map( function( $p ) {
					return 'Disallow: ' . sanitize_text_field( $p );
				}, $disallow );
				$allow = array_unique( $allow );
				$allow = array_map( function( $p ) {
					return 'Allow: ' . sanitize_text_field( $p );
				}, $allow );

				if ( count( $allow ) > 0 ) {
					$content .= implode( "\n", $allow );
					$content .= "\n";
				}
				if ( count( $disallow ) > 0 ) {
					$content .= implode( "\n", $disallow );
					$content .= "\n";
				}

				$content .= "\n";

			}
		}

		file_put_contents( $robots_path, $content );
	}

	/**
	 * Sanitize the useragent settings
	 *
	 * @param array $useragents
	 *
	 * @return array
	 */
	public static function sanitize_robots_useragent( $useragents ) {
		return array_map( function( $ua ) {
			$ua['allow'] = is_array( $ua['allow'] ) ? $ua['allow'] : json_decode( $ua['allow'] );
			$ua['disallow'] = is_array( $ua['disallow'] ) ? $ua['disallow'] : json_decode( $ua['disallow'] );

			return [
				'useragent' => sanitize_text_field( $ua['useragent'] ),
				'crawl_rate' => Utilities::sanitize_int( $ua['crawl_rate'] ),
				'restrict_wp_admin' => Utilities::sanitize_bool( $ua['restrict_wp_admin'] ),
				'allow_wp_ajax' => Utilities::sanitize_bool( $ua['allow_wp_ajax'] ),
				'disallow' => array_map( 'sanitize_text_field', $ua['disallow'] ),
				'allow' => array_map( 'sanitize_text_field', $ua['allow'] ),
			];
		}, $useragents );
	}
}
